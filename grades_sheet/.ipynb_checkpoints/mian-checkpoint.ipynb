{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ecb90d6a-e3c2-4c7d-b28a-4a285123b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter.ttk import Button, Label, Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf3c321c-3bad-40cf-8473-5733aaca97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained SVM models for digits and symbols\n",
    "DIGIT_MODEL_PATH = \"./digits_model.joblib\"\n",
    "SYMBOL_MODEL_PATH = \"./symbols_model.joblib\"\n",
    "digit_model = joblib.load(DIGIT_MODEL_PATH)\n",
    "symbol_model = joblib.load(SYMBOL_MODEL_PATH)\n",
    "# Configure Tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d94563d7-852b-47da-9d93-1b6378baee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper extraction\n",
    "def preprocess_image_paper(input_img):\n",
    "    # Converts the input image to grayscale and applies edge detection.\n",
    "    img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(img_gray, 100, 255)  # Edge detection\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    edges_dilated = cv2.dilate(edges, kernel, iterations=2)  # Dilate edges\n",
    "    cv2.imwrite('./processing/extract-paper/edges_dilated.jpg',edges_dilated)\n",
    "    return img_gray, edges_dilated\n",
    "\n",
    "def find_largest_contour(edges):\n",
    "    # Finds the largest quadrilateral contour in the image.\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contour = None\n",
    "    max_area = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        if area > max_area and len(approx) == 4:\n",
    "            max_area = area\n",
    "            largest_contour = approx\n",
    "\n",
    "    return largest_contour\n",
    "\n",
    "def warp_perspective(img, contour):\n",
    "    # Warps the perspective of the input image to align the given contour.\n",
    "    reordered_contour = reorder_points(contour)\n",
    "    h, w = img.shape[:2]\n",
    "    src_pts = np.array(reordered_contour, dtype=np.float32)\n",
    "    dst_pts = np.array([[0, 0], [w, 0], [0, h], [w, h]], dtype=np.float32)\n",
    "    transformation_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    warped_image = cv2.warpPerspective(img, transformation_matrix, (w, h))\n",
    "    return warped_image\n",
    "def reorder_points(points):\n",
    "    # Reorders the given points to ensure they are in the order:\n",
    "    # Top-left, Top-right, Bottom-left, Bottom-right.\n",
    "    points = points.reshape((4, 2))\n",
    "    reordered = np.zeros((4, 1, 2), dtype=np.int32)\n",
    "    sum_points = points.sum(axis=1)\n",
    "    diff_points = np.diff(points, axis=1)\n",
    "    \n",
    "    reordered[0] = points[np.argmin(sum_points)]  # Top-left\n",
    "    reordered[3] = points[np.argmax(sum_points)]  # Bottom-right\n",
    "    reordered[1] = points[np.argmin(diff_points)]  # Top-right\n",
    "    reordered[2] = points[np.argmax(diff_points)]  # Bottom-left\n",
    "    return reordered\n",
    "\n",
    "def extract_paper(input_img):\n",
    "    output_img = input_img\n",
    "    img_gray, edges = preprocess_image_paper(output_img)\n",
    "    largest_contour = find_largest_contour(edges)\n",
    "    if largest_contour is None:\n",
    "        raise ValueError(\"No paper-like region found in the image.\")\n",
    "    output_img = warp_perspective(img_gray, largest_contour)\n",
    "    cv2.imwrite('./processing/extract-paper/image_after_extracting_paper.jpg',output_img)\n",
    "    return output_img\n",
    "# explanation\n",
    "#1-apply canny for edge detection then dilate\n",
    "#2-find largest rect contour of the dilated image\n",
    "#3- warp_perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6acd5147-03ea-4123-90db-712c10da3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid extraction\n",
    "def preprocess_image_grid(img):\n",
    "    #Convert the image to grayscale and apply binary thresholding.#\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return 255 - img_bin  # Invert binary image\n",
    "\n",
    "\n",
    "def remove_image_borders(img, border_size=20):\n",
    "    #Remove borders from the image by setting pixels near edges to zero.#\n",
    "    img[:border_size, :] = 0\n",
    "    img[-border_size:, :] = 0\n",
    "    img[:, :border_size] = 0\n",
    "    img[:, -border_size:] = 0\n",
    "    return img\n",
    "\n",
    "def compare_contours(a, b):\n",
    "    x_a, y_a, _, _ = cv2.boundingRect(a)\n",
    "    x_b, y_b, _, _ = cv2.boundingRect(b)\n",
    "    # Compare x-coordinates if sufficiently different, else compare y-coordinates\n",
    "    if abs(x_a - x_b) > 7:\n",
    "        return x_a - x_b\n",
    "    return y_a - y_b\n",
    "\n",
    "def extract_lines(img, kernel_size, orientation='vertical'):\n",
    "    #Extract vertical or horizontal lines using morphological operations.#\n",
    "    if orientation == 'vertical':\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_size))\n",
    "    else:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, 1))\n",
    "\n",
    "    eroded = cv2.erode(img, kernel, iterations=3)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations=3)\n",
    "    return dilated\n",
    "    \n",
    "def sort_contours(contours):\n",
    "    return sorted(contours, key=cmp_to_key(compare_contours))\n",
    "\n",
    "def draw_hough_lines(img, lines, orientation='vertical'):\n",
    "    #Draw Hough lines to enhance line segments.#\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if orientation == 'vertical':\n",
    "                cv2.line(img, (x1, 0), (x2, img.shape[0]), (255, 255, 255), 1)\n",
    "            else:\n",
    "                cv2.line(img, (0, y1), (img.shape[1], y2), (255, 255, 255), 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_grid(img):\n",
    "    #Extract the grid structure and return individual cell images.#\n",
    "    # Preprocess the image\n",
    "    img_bin = preprocess_image_grid(img)\n",
    "    img_bin = remove_image_borders(img_bin)\n",
    "\n",
    "    # Extract vertical and horizontal lines\n",
    "    kernel_length = img_bin.shape[1] // 30\n",
    "    vertical_lines = extract_lines(img_bin, kernel_length, 'vertical')\n",
    "    horizontal_lines = extract_lines(img_bin, kernel_length, 'horizontal')\n",
    "\n",
    "    # Apply Hough Transform to enhance lines\n",
    "    vertical_hough = cv2.HoughLinesP(vertical_lines, 1, np.pi / 180, 127, minLineLength=20, maxLineGap=10)\n",
    "    horizontal_hough = cv2.HoughLinesP(horizontal_lines, 2, np.pi / 180, 127, minLineLength=20, maxLineGap=10)\n",
    "    \n",
    "    if vertical_hough is not None:\n",
    "        vertical_lines = draw_hough_lines(vertical_lines, vertical_hough, 'vertical')\n",
    "    if horizontal_hough is not None:\n",
    "        horizontal_lines = draw_hough_lines(horizontal_lines, horizontal_hough, 'horizontal')\n",
    "\n",
    "    # Combine vertical and horizontal lines to form the grid\n",
    "    grid_img = cv2.bitwise_and(vertical_lines, horizontal_lines)\n",
    "    general_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    grid_img = cv2.dilate(grid_img, general_kernel, iterations=3)\n",
    "    grid_img = cv2.erode(grid_img, general_kernel, iterations=1)\n",
    "\n",
    "    # Find and sort contours\n",
    "    contours, _ = cv2.findContours(grid_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sort_contours(contours)\n",
    "\n",
    "    # Detect rows and columns\n",
    "    rows = []\n",
    "    for idx in range(len(contours) - 1):\n",
    "        x1, y1, _, _ = cv2.boundingRect(contours[idx])\n",
    "        x2, y2, _, _ = cv2.boundingRect(contours[idx + 1])\n",
    "        rows.append(y1)\n",
    "        if x1 != x2:  # Break if a new column starts\n",
    "            break\n",
    "\n",
    "    num_rows = len(rows)\n",
    "    num_columns = len(contours) // num_rows\n",
    "    grid = []\n",
    "\n",
    "    # Extract grid cells\n",
    "    for row_idx in range(1, num_rows - 1):\n",
    "        grid_row = []\n",
    "        for col_idx in range(num_columns - 1):\n",
    "            \n",
    "            x1, y1, w1, h1 = cv2.boundingRect(contours[row_idx + col_idx * num_rows])\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(contours[row_idx + col_idx * num_rows + 1])\n",
    "            x3, y3, w3, h3 = cv2.boundingRect(contours[row_idx + (col_idx + 1) * num_rows + 1])\n",
    "\n",
    "            # Crop the cell from the original image\n",
    "            cell_img = img[y1 + h1: y3, x2 + w2: x3]\n",
    "            grid_row.append(cell_img)\n",
    "\n",
    "        grid.append(grid_row)\n",
    "\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "061f5aba-7e66-470c-9521-184f13a485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_data_extraction\n",
    "\n",
    "HOG_IMG_SIZE = (32, 32)\n",
    "\n",
    "def extract_hog_features(img):\n",
    "    #Extract HOG features from an image.#\n",
    "    if img is None or img.size == 0:\n",
    "        return None\n",
    "    img_resized = cv2.resize(img, HOG_IMG_SIZE)\n",
    "    win_size = HOG_IMG_SIZE\n",
    "    block_size = (8, 8)  # Block size in pixels\n",
    "    block_stride = (4, 4)  # Block stride in pixels\n",
    "    cell_size = (4, 4)  # Cell size in pixels\n",
    "    nbins = 9  # Number of bins for the histogram\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    return hog.compute(img_resized).flatten()\n",
    "\n",
    "def read_arabic_text(img):\n",
    "    _, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    text = pytesseract.image_to_string(img_bin, lang='ara', config=\"--psm 6 --oem 3\")\n",
    "    return text\n",
    "\n",
    "def read_english_text(img):\n",
    "    _, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    text = pytesseract.image_to_string(img_bin, lang='eng', config=\"--psm 6 --oem 3\")\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def predict_digit(img, use_ocr=False):\n",
    "    #Predict a digit using OCR or SVM.#\n",
    "    if use_ocr:\n",
    "        _, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        return pytesseract.image_to_string(\n",
    "            img_bin, config=\"--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789\"\n",
    "        )\n",
    "    hog_features = extract_hog_features(img)\n",
    "    if hog_features is None:\n",
    "        return \"\"\n",
    "    return digit_model.predict([hog_features])[0]\n",
    "\n",
    "\n",
    "def predict_symbol(img):\n",
    "    #Predict a symbol using the SVM model.#\n",
    "    hog_features = extract_hog_features(img)\n",
    "    if hog_features is None:\n",
    "        return \"\"\n",
    "    return symbol_model.predict([hog_features])[0]\n",
    "\n",
    "\n",
    "def segment_image(img):\n",
    "    #Segment an image to extract contours.#\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    edged = cv2.Canny(blurred, 50, 200)\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr))\n",
    "    return [(cv2.boundingRect(contour)) for contour in contours if cv2.contourArea(contour) > 50]\n",
    "\n",
    "\n",
    "def get_id_from_image(img, use_ocr=True):\n",
    "    #Extract the ID from an image.#\n",
    "    if use_ocr:\n",
    "        return pytesseract.image_to_string(img)\n",
    "    img_resized = cv2.resize(img, (128, 64))\n",
    "    contours = segment_image(img_resized)\n",
    "    predictions = [predict_digit(img[y:y+h, x:x+w]) for x, y, w, h in contours]\n",
    "    return \"\".join(map(str, predictions))\n",
    "\n",
    "\n",
    "def map_symbol_to_value(symbol):\n",
    "    #Convert symbolic string to a numeric value.#\n",
    "    mappings = {\n",
    "        \"box\": 0,\n",
    "        \"correct\": 5,\n",
    "        \"empty\": -1,\n",
    "        \"question\": -2\n",
    "    }\n",
    "    if symbol in mappings:\n",
    "        return mappings[symbol]\n",
    "    if symbol.startswith(\"horizontal\") and symbol[10:].isdigit():\n",
    "        return 5 - int(symbol[10:])\n",
    "    if symbol.startswith(\"vertical\") and symbol[8:].isdigit():\n",
    "        return int(symbol[8:])\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_data_from_grid(grid, use_ocr_id=True, use_ocr_digit=False):\n",
    "    #Extract structured data from a grid of images.#\n",
    "    print(len(grid[0]))\n",
    "    data = [[\"Code\",\"اسم الطالب\",\"Student Name In English\", \"1\", \"2\", \"3\"]]\n",
    "    for row in grid:\n",
    "        row_data = []\n",
    "        for idx, cell in enumerate(row):\n",
    "            if idx == 0:\n",
    "                row_data.append(get_id_from_image(cell, use_ocr_id))\n",
    "            elif idx == 1:\n",
    "                row_data.append(read_arabic_text(cell))\n",
    "            elif idx == 2:\n",
    "                row_data.append(read_english_text(cell))\n",
    "            elif idx == 3:\n",
    "                row_data.append(predict_digit(cell, use_ocr_digit))\n",
    "            else:\n",
    "                row_data.append(map_symbol_to_value(predict_symbol(cell)))\n",
    "        data.append(row_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "403b0742-1224-411e-bf1f-dd769ead7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_excel_sheet\n",
    "def generate_excel_sheet(data=None, file_path='./new-output.xlsx', skip_value=-1, highlight_value=-2, highlight_color=\"FF0000\"):\n",
    "    if data is None:\n",
    "        data = []        \n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    # Create a new Excel workbook and select the active sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Populate data into the sheet\n",
    "    for row_idx, row_data in enumerate(data, start=1):\n",
    "        for col_idx, value in enumerate(row_data, start=1):\n",
    "            if value == skip_value:\n",
    "                continue\n",
    "            cell = sheet.cell(row=row_idx, column=col_idx, value=\"\" if value == highlight_value else value)\n",
    "            if value == highlight_value:\n",
    "                cell.fill = PatternFill(start_color=highlight_color, end_color=highlight_color, fill_type='solid')\n",
    "\n",
    "    workbook.save(file_path) #in disk\n",
    "    # Save the workbook to a binary stream for in-memory usage\n",
    "    excel_buffer = BytesIO()\n",
    "    workbook.save(excel_buffer)\n",
    "     # Reset buffer pointer to the start because the writing moves cursor to the end\n",
    "    excel_buffer.seek(0) \n",
    "    return excel_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "00cf8982-534c-4f7f-9e71-fa01770ba81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# the main\n",
    "#todo:\n",
    "# why -1 and -2\n",
    "# add exctracting the names\n",
    "# add gui\n",
    "#grid_data_extraction test the old code\n",
    "\n",
    "input_image = cv2.imread('./1.jpg', cv2.IMREAD_COLOR)\n",
    "extracted_paper_image = extract_paper(input_image)\n",
    "extracted_grid = extract_grid(extracted_paper_image)\n",
    "extracted_data_from_grid = extract_data_from_grid(\n",
    "extracted_grid, use_ocr_id=True, use_ocr_digit=False)\n",
    "excel_buffer = generate_excel_sheet(extracted_data_from_grid,'./updated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "582f4b9e-c810-4959-bcff-3aa12d135eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def process_image(status_label):\n",
    "    file_types = [('Jpg Files', '*.jpg')]\n",
    "    selected_files = filedialog.askopenfilenames(\n",
    "        multiple=True, filetypes=file_types, title='Select Image Files'\n",
    "    )\n",
    "\n",
    "    for file_path in selected_files:\n",
    "        try:\n",
    "            # Update the status label with the current file name\n",
    "            status_label.config(text=f\"Processing: {os.path.basename(file_path)}\")\n",
    "            status_label.update_idletasks()\n",
    "\n",
    "            input_image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "            extracted_paper_image = extract_paper(input_image)\n",
    "            extracted_grid = extract_grid(extracted_paper_image)\n",
    "            extracted_data_from_grid = extract_data_from_grid(\n",
    "                extracted_grid, use_ocr_id=True, use_ocr_digit=False\n",
    "            )\n",
    "            save_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=\".xlsx\",\n",
    "                filetypes=[(\"Excel Files\", \"*.xlsx\")],\n",
    "            )\n",
    "            if not save_path:\n",
    "                return\n",
    "\n",
    "            excel_buffer = generate_excel_sheet(extracted_data_from_grid, save_path)\n",
    "            messagebox.showinfo(\"Success\", f\"Data saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            # Clear the status label after processing\n",
    "            status_label.config(text=\"\")\n",
    "\n",
    "def create_gui():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Grades Sheet Extractor\")\n",
    "    root.geometry(\"400x200\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Grades Sheet Extraction Tool\", font=(\"Helvetica\", 16))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "    status_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 12), fg=\"blue\")\n",
    "    status_label.pack(pady=5)\n",
    "\n",
    "    button = tk.Button(\n",
    "        root, \n",
    "        text=\"Select Images and Process\", \n",
    "        command=lambda: process_image(status_label), \n",
    "        font=(\"Helvetica\", 12)\n",
    "    )\n",
    "    button.pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_gui()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
